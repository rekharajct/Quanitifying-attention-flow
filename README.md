# Quanitifying attention flow in Transformers

<!-- ABOUT THE PROJECT -->
## Description

This directory contains the implementation of the paper Quantifying Attention Flow in Transformers by Samira Abnanar and Willem Zuidema      
     
     
## To train the verb-number classifier
```
python bert_sv_train.py
```
## To find the attention matrices and relevance scores
```
python sv_find_attention.py
```
## To get the results of correlation scores

```
python sv_attention_results_sci_raw_sum.py

```

## References
```
[Quantifying Attention Flow in Transformers](https://aclanthology.org/2020.acl-main.385) (Abnar & Zuidema, ACL 2020)

```
